{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7683351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install diffusers from source if needed\n",
    "# as the fluxpipeline is brand new\n",
    "\n",
    "# !pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b3b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall transformer-engine -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db292f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acb8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bacceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54d0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall apex -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a828839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95edf25a",
   "metadata": {},
   "source": [
    "## doesnt work (37-48mins estimated for a single image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0496e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from diffusers import FluxPipeline\n",
    "\n",
    "# pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "# pipe.enable_model_cpu_offload()\n",
    "\n",
    "# prompt = \"a tiny astronaut hatching from an egg on the moon\"\n",
    "# out = pipe(\n",
    "#     prompt=prompt,\n",
    "#     guidance_scale=1.5,\n",
    "#     height=1024,\n",
    "#     width=1024,\n",
    "#     num_inference_steps=25,\n",
    "# ).images[0]\n",
    "# out.save(\"image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19999d77",
   "metadata": {},
   "source": [
    "## FP8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49a2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optimum-quanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a1ba64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a07920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43af679",
   "metadata": {},
   "source": [
    "### setup pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b72250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95423f8e82c64a5281bcff6d75832268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae924c093efc430dbc8d0e7bf5f51f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9005a3952424004a0c724eeb6a8bdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a391bf88f00b4a7486737edb6773a114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxTransformer2DModel, FluxPipeline\n",
    "from transformers import T5EncoderModel, CLIPTextModel\n",
    "from optimum.quanto import freeze, qfloat8, quantize\n",
    "\n",
    "bfl_repo = \"black-forest-labs/FLUX.1-dev\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "transformer = FluxTransformer2DModel.from_single_file(\"https://huggingface.co/Kijai/flux-fp8/blob/main/flux1-dev-fp8.safetensors\", torch_dtype=dtype)\n",
    "quantize(transformer, weights=qfloat8)\n",
    "freeze(transformer)\n",
    "\n",
    "text_encoder_2 = T5EncoderModel.from_pretrained(bfl_repo, subfolder=\"text_encoder_2\", torch_dtype=dtype)\n",
    "quantize(text_encoder_2, weights=qfloat8)\n",
    "freeze(text_encoder_2)\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(bfl_repo, transformer=None, text_encoder_2=None, torch_dtype=dtype)\n",
    "pipe.transformer = transformer\n",
    "pipe.text_encoder_2 = text_encoder_2\n",
    "\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "prompt = \"A cat holding a sign that says hello world\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=1.5,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=20,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "\n",
    "image.save(\"flux-fp8-dev.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42aedd2",
   "metadata": {},
   "source": [
    "### test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4c7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"A cat holding a sign that says 'i am stupid'\"\n",
    "# image = pipe(\n",
    "#     prompt,\n",
    "#     guidance_scale=1.5,\n",
    "#     height=1024,\n",
    "#     width=1024,\n",
    "#     output_type=\"pil\",\n",
    "#     num_inference_steps=20,\n",
    "#     generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    "# ).images[0]\n",
    "\n",
    "# image.save(\"flux-fp8-dev-2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26bc824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"A cat holding a sign that says 'i love cheese'\"\n",
    "# image = pipe(\n",
    "#     prompt,\n",
    "#     guidance_scale=1.5,\n",
    "#     height=1024,\n",
    "#     width=1024,\n",
    "#     output_type=\"pil\",\n",
    "#     num_inference_steps=20,\n",
    "#     generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    "# ).images[0]\n",
    "\n",
    "# image.save(\"flux-fp8-dev-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e571f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prompt = \"picture of a delicious cheeseburger with fries on the side, in the forest, nature background\"\n",
    "# image = pipe(\n",
    "#     prompt,\n",
    "#     guidance_scale=1.5,\n",
    "#     height=1024,\n",
    "#     width=1024,\n",
    "#     output_type=\"pil\",\n",
    "#     num_inference_steps=20,\n",
    "#     generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    "# ).images[0]\n",
    "\n",
    "# image.save(\"flux-fp8-dev-4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2636d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Amuse-Bouche Crispy Parmesan waffle with tomato and basil gelée, 4k food photography, top down picture of a plate, michelin starred dish\"\n",
    "# image = pipe(\n",
    "#     prompt,\n",
    "#     guidance_scale=1.5,\n",
    "#     height=1024,\n",
    "#     width=1024,\n",
    "#     output_type=\"pil\",\n",
    "#     num_inference_steps=25,\n",
    "#     generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    "# ).images[0]\n",
    "\n",
    "# image.save(\"food-test-2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a3ca237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d65f7522e948f6997e432980427eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Amuse-Bouche Crispy Parmesan waffle with tomato and basil gelée, 4k food photography, top down picture of a plate, michelin starred dish\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=1.5,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=25,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "\n",
    "image.save(\"food-test-4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f37da8",
   "metadata": {},
   "source": [
    "We find that 25 steps with the above prompt template is the ideal config to run all 288 food prompts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb496791",
   "metadata": {},
   "source": [
    "### Process all 288 prompts\n",
    "\n",
    "We load a datasets of prompts and filenames and pass it to the image generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79e6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the seed to a fixed 42\n",
    "def from_prompt_to_file(prompt, filename):\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=1.5,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        output_type=\"pil\",\n",
    "        num_inference_steps=25,\n",
    "        generator=torch.Generator(\"cpu\").manual_seed(42)\n",
    "    ).images[0]\n",
    "\n",
    "    image.save('images/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fae4041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amuse-Bouche Crispy Parmesan waffle with tomat...</td>\n",
       "      <td>Chef_Laurent_Dupont-L'Etoile_d'Or-Amuse-Bouche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Appetizer Caramelized scallops with cauliflowe...</td>\n",
       "      <td>Chef_Laurent_Dupont-L'Etoile_d'Or-Appetizer-Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soup Velvety butternut squash bisque with crèm...</td>\n",
       "      <td>Chef_Laurent_Dupont-L'Etoile_d'Or-Soup-Velvety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fish Pan-seared turbot with Jerusalem artichok...</td>\n",
       "      <td>Chef_Laurent_Dupont-L'Etoile_d'Or-Fish-Pan-sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meat Roasted duck breast with figs, purple pot...</td>\n",
       "      <td>Chef_Laurent_Dupont-L'Etoile_d'Or-Meat-Roasted...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Amuse-Bouche Crispy Parmesan waffle with tomat...   \n",
       "1  Appetizer Caramelized scallops with cauliflowe...   \n",
       "2  Soup Velvety butternut squash bisque with crèm...   \n",
       "3  Fish Pan-seared turbot with Jerusalem artichok...   \n",
       "4  Meat Roasted duck breast with figs, purple pot...   \n",
       "\n",
       "                                            filename  \n",
       "0  Chef_Laurent_Dupont-L'Etoile_d'Or-Amuse-Bouche...  \n",
       "1  Chef_Laurent_Dupont-L'Etoile_d'Or-Appetizer-Ca...  \n",
       "2  Chef_Laurent_Dupont-L'Etoile_d'Or-Soup-Velvety...  \n",
       "3  Chef_Laurent_Dupont-L'Etoile_d'Or-Fish-Pan-sea...  \n",
       "4  Chef_Laurent_Dupont-L'Etoile_d'Or-Meat-Roasted...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the prompt dataset\n",
    "import pandas as pd\n",
    "\n",
    "prompt_df = pd.read_csv('food_prompts_and_filenames.csv', index_col=0)\n",
    "prompt_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862514c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0543de5b8ca54ec093dab56fd1626dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b4f2bcfd364a588ec1ad730837bd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960a3f7f8c684a9786eaa40d6ca4fd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4700eecca0094726b194ccc836a9a628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcbaaa91ece4cdca89cfcf32be87264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfc27ee089043149aeda68ae4bfd208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73725e274c2345e38fccdac6491fd945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfd2bed4da2414d9dfab9de6d6fcbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a7da63149f430d954e5cce84c51b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "prompt_df.progress_apply(lambda row: from_prompt_to_file(row['prompt'], row['filename']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6c172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
